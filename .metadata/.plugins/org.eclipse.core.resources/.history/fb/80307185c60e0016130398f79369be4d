package com.bda.kafka;
import java.io.File;
import java.io.FileInputStream;
import java.io.IOException;
import java.io.InputStream;
import java.io.UnsupportedEncodingException;
import java.nio.ByteBuffer;
import java.util.HashMap;
import java.util.List;
import java.util.Map;
import java.util.Properties;

import kafka.consumer.Consumer;
import kafka.consumer.ConsumerConfig;
import kafka.consumer.ConsumerIterator;
import kafka.consumer.KafkaStream;
import kafka.javaapi.consumer.ConsumerConnector;
import kafka.javaapi.message.ByteBufferMessageSet;
import kafka.message.MessageAndOffset;



public class BDAKafkaConsumer extends Thread {
	
	static Properties prop;
	static{
		 prop = new Properties();
		try {
//			File configDir = new File(System.getProperty("catalina.base"), "conf");
//			File configFile = new File(configDir, "myconfig.properties");
			InputStream stream = new FileInputStream(new File("myconfig.properties"));
			Properties props = new Properties();
			props.load(stream);
//			prop.load(new UBFKafkaProducer().getClass().getResourceAsStream("/com/ubf/resource/config.properties"));
		} catch (IOException e) {
			// TODO Auto-generated catch block
			e.printStackTrace();
		}
	}
	
//	final static String clientId = "SimpleConsumerDemoClient";
    final static String TOPIC = prop.getProperty("topic");
    ConsumerConnector consumerConnector;


//    public static void main(String[] argv) throws UnsupportedEncodingException {
//    	KafkaConsumer kafkaConsumer = new KafkaConsumer();
//    	kafkaConsumer.start();
//    }

    public BDAKafkaConsumer(){
        Properties properties = new Properties();
        properties.put("zookeeper.connect",prop.getProperty("zookeeper_connect"));
        properties.put("metadata.broker.list", prop.getProperty("broker_list"));
        properties.put("group.id",prop.getProperty("group_id"));
        properties.put("auto.offset.reset", prop.getProperty("auto_offset_reset")); 

        ConsumerConfig consumerConfig = new ConsumerConfig(properties);
        consumerConnector = Consumer.createJavaConsumerConnector(consumerConfig);

    }

    @Override
    public void run() {
    	// long readOffset = getLastOffset(kafka.api.OffsetRequest.EarliestTime(), clientName);
        Map<String, Integer> topicCountMap = new HashMap<String, Integer>();
        topicCountMap.put(TOPIC, new Integer(1));
        Map<String, List<KafkaStream<byte[], byte[]>>> consumerMap = consumerConnector.createMessageStreams(topicCountMap);
//        System.out.println(consumerMap);
        System.out.println(consumerMap.get(TOPIC).get(0).size());
         
        System.out.println("111111");
        KafkaStream<byte[], byte[]> stream =  consumerMap.get(TOPIC).get(0);
        ConsumerIterator<byte[], byte[]> it = stream.iterator();
        System.out.println(it.size());
        while(it.hasNext())
            System.out.println(new String(it.next().message()));

    }

    public static String getMessages(ByteBufferMessageSet messageSet) throws UnsupportedEncodingException {
        for(MessageAndOffset messageAndOffset: messageSet) {
            ByteBuffer payload = messageAndOffset.message().payload();
            byte[] bytes = new byte[payload.limit()];
            payload.get(bytes);
            System.out.println(new String(bytes, "UTF-8"));
            return new String(bytes, "UTF-8");
        }
		return "";
    }

}
