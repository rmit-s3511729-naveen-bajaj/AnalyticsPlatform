package com.bda.kafka;
import java.io.File;
import java.io.FileInputStream;
import java.io.IOException;
import java.io.InputStream;
import java.io.UnsupportedEncodingException;
import java.nio.ByteBuffer;
import java.util.HashMap;
import java.util.List;
import java.util.Map;
import java.util.Properties;

import kafka.consumer.Consumer;
import kafka.consumer.ConsumerConfig;
import kafka.consumer.ConsumerIterator;
import kafka.consumer.KafkaStream;
import kafka.javaapi.consumer.ConsumerConnector;
import kafka.javaapi.message.ByteBufferMessageSet;
import kafka.message.MessageAndOffset;



public class BDAKafkaConsumer{
	
	static Properties prop;
	static{
		 prop = new Properties();
		try {
//			File configDir = new File(System.getProperty("catalina.base"), "conf");
//			File configFile = new File(configDir, "myconfig.properties");
			InputStream stream = new FileInputStream(new File("myconfig.properties"));
			Properties props = new Properties();
			props.load(stream);
			 System.out.println("--"+props.getProperty("zookeeper_connect"));
//			prop.load(new UBFKafkaProducer().getClass().getResourceAsStream("/com/ubf/resource/config.properties"));
		} catch (IOException e) {
			// TODO Auto-generated catch block
			e.printStackTrace();
		}
	}

    final static String TOPIC = prop.getProperty("topic");
    ConsumerConnector consumerConnector;


    public BDAKafkaConsumer(){
    	prop = new Properties();
    	try{
    	InputStream stream = new FileInputStream(new File("myconfig.properties"));
		Properties props = new Properties();
		props.load(stream);
		 System.out.println("--"+props.getProperty("zookeeper_connect"));
    	}catch(Exception e){
    		e.printStackTrace();
    	}
    	connection();
    	retrieveMessage();
    	

    }

    private void connection() {
    	  Properties properties = new Properties();
    	  
          properties.put("zookeeper.connect",prop.getProperty("zookeeper_connect"));
          properties.put("metadata.broker.list", prop.getProperty("broker_list"));
          properties.put("group.id",prop.getProperty("group_id"));
          properties.put("auto.offset.reset", prop.getProperty("auto_offset_reset")); 

          ConsumerConfig consumerConfig = new ConsumerConfig(properties);
          consumerConnector = Consumer.createJavaConsumerConnector(consumerConfig);
		
	}


    private void retrieveMessage() {
    	// long readOffset = getLastOffset(kafka.api.OffsetRequest.EarliestTime(), clientName);
        Map<String, Integer> topicCountMap = new HashMap<String, Integer>();
        topicCountMap.put(TOPIC, new Integer(1));
        Map<String, List<KafkaStream<byte[], byte[]>>> consumerMap = consumerConnector.createMessageStreams(topicCountMap);
//        System.out.println(consumerMap);
        System.out.println(consumerMap.get(TOPIC).get(0).size());
         
        System.out.println("111111");
        KafkaStream<byte[], byte[]> stream =  consumerMap.get(TOPIC).get(0);
        ConsumerIterator<byte[], byte[]> it = stream.iterator();
        count = it.size();
        System.out.println(it.size());
        while(it.hasNext())
            System.out.println(new String(it.next().message()));

    }
     int count;
     public int getMessageCount(){
    	 return count;
     }
//    public String getMessages() throws UnsupportedEncodingException {
//        for(MessageAndOffset messageAndOffset: messageSet) {
//            ByteBuffer payload = messageAndOffset.message().payload();
//            byte[] bytes = new byte[payload.limit()];
//            payload.get(bytes);
//            System.out.println(new String(bytes, "UTF-8"));
//            return new String(bytes, "UTF-8");
//        }
//		return "";
//    }

}
